{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"06_ling_classif_performance.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"colab_type":"text","id":"3nUFFixdJbqY"},"cell_type":"markdown","source":["# RE19-linguistic-classification: performance evaluation\n","\n","This notebook evaluates the performance of a F and Q requirements classifiers using different linguistic features."]},{"metadata":{"colab_type":"text","id":"c4LfzHoKRUwk"},"cell_type":"markdown","source":["## 0. Set up (optional)\n","\n","Run the following install functions if running Jupyter on a cloud environment like Colaboratory, which does not allow you to install the libraries permanently on your local machine"]},{"metadata":{"colab_type":"code","id":"inoDnAn5savZ","outputId":"af0c1c24-b6e0-45d8-fbad-2fcb8e891afe","executionInfo":{"status":"ok","timestamp":1554724971226,"user_tz":-120,"elapsed":76529,"user":{"displayName":"Davide Dell'Anna","photoUrl":"https://lh5.googleusercontent.com/-dJU__MJ08Ww/AAAAAAAAAAI/AAAAAAAAbsA/YkubKaeFgQo/s64/photo.jpg","userId":"01259263475584376287"}},"colab":{"base_uri":"https://localhost:8080/","height":864}},"cell_type":"code","source":["!git clone https://github.com/rulematrix/rule-matrix-py.git\n","!pip3 install rule-matrix-py/.\n","!pip3 install mdlp-discretization\n","!pip3 install pysbrl==0.4.2rc0\n","!pip3 install fim\n","!pip3 install cython numpy\n","!pip3 install skope-rules"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cloning into 'rule-matrix-py'...\n","remote: Enumerating objects: 169, done.\u001b[K\n","remote: Total 169 (delta 0), reused 0 (delta 0), pack-reused 169\u001b[K\n","Receiving objects: 100% (169/169), 1.47 MiB | 4.06 MiB/s, done.\n","Resolving deltas: 100% (79/79), done.\n","Processing ./rule-matrix-py\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from rulematrix==0.1) (1.14.6)\n","Building wheels for collected packages: rulematrix\n","  Building wheel for rulematrix (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/89/26/fb/f7460d89e367d1041e50df2118d4b52b0c9a89eb2bc9a50381\n","Successfully built rulematrix\n","Installing collected packages: rulematrix\n","Successfully installed rulematrix-0.1\n","Collecting mdlp-discretization\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/6f/96722189bc15a9603c5b0f9ff223534683eae75130e8a67eac407ba7c6bd/mdlp_discretization-0.3.2-cp36-cp36m-manylinux1_x86_64.whl (189kB)\n","\u001b[K    100% |████████████████████████████████| 194kB 10.3MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from mdlp-discretization) (1.14.6)\n","Requirement already satisfied: scikit-learn>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from mdlp-discretization) (0.20.3)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from mdlp-discretization) (1.1.0)\n","Installing collected packages: mdlp-discretization\n","Successfully installed mdlp-discretization-0.3.2\n","Collecting pysbrl==0.4.2rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/bc/aa1501691f0209de87a7bb97be9c9101fabbb8178ecd334a3833cbc98933/pysbrl-0.4.2rc0-cp36-cp36m-manylinux1_x86_64.whl (950kB)\n","\u001b[K    100% |████████████████████████████████| 952kB 10.1MB/s \n","\u001b[?25hInstalling collected packages: pysbrl\n","Successfully installed pysbrl-0.4.2rc0\n","Collecting fim\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/a8/66fbb303236eb7e4caa63096814aa2675073f20aee95104920636af84a7e/fim-6.27.tar.gz (343kB)\n","\u001b[K    100% |████████████████████████████████| 348kB 8.4MB/s \n","\u001b[?25hBuilding wheels for collected packages: fim\n","  Building wheel for fim (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/5c/1c/94/b96c6b9a2eb858e26a675f86a908abfa53a593185b1c058823\n","Successfully built fim\n","Installing collected packages: fim\n","Successfully installed fim-6.27\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.14.6)\n","Requirement already satisfied: skope-rules in /usr/local/lib/python3.6/dist-packages (1.0.0)\n","Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from skope-rules) (0.22.0)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from skope-rules) (1.14.6)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from skope-rules) (1.1.0)\n","Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from skope-rules) (0.20.3)\n","Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.1->skope-rules) (2.5.3)\n","Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.1->skope-rules) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas>=0.18.1->skope-rules) (1.11.0)\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"D9z9eI1OReXJ"},"cell_type":"markdown","source":["## 1. Import libraries"]},{"metadata":{"colab_type":"code","id":"5nFWJMhhsjed","outputId":"1f07809a-c759-4c30-d7fb-4564bd45cd46","executionInfo":{"status":"ok","timestamp":1554732566751,"user_tz":-120,"elapsed":2468,"user":{"displayName":"Davide Dell'Anna","photoUrl":"https://lh5.googleusercontent.com/-dJU__MJ08Ww/AAAAAAAAAAI/AAAAAAAAbsA/YkubKaeFgQo/s64/photo.jpg","userId":"01259263475584376287"}},"colab":{"base_uri":"https://localhost:8080/","height":17}},"cell_type":"code","source":["import rulematrix\n","from rulematrix.surrogate import rule_surrogate\n","from sklearn.neural_network import MLPClassifier\n","from sklearn import svm\n","from sklearn.svm import SVC\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import cross_validate, StratifiedKFold\n","from sklearn.metrics import recall_score, precision_score, f1_score, roc_curve, precision_recall_curve, auc, confusion_matrix, roc_auc_score\n","from imblearn.over_sampling import ADASYN \n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import load_breast_cancer, load_iris\n","\n","import matplotlib.pyplot as plt\n","from matplotlib import cm\n","from scipy import interp\n","\n","import numpy as np\n","import pandas as pd\n","\n","from skrules import SkopeRules\n","\n","# Set the ipython display in such a way that helps the visualization of the rulematrix outputs.\n","from IPython.display import display, HTML\n","\n","display(HTML(data=\"\"\"\n","<style>\n","    div#notebook-container    { width: 95%; }\n","    div#menubar-container     { width: 65%; }\n","    div#maintoolbar-container { width: 99%; }\n","</style>\n","\"\"\"))"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","<style>\n","    div#notebook-container    { width: 95%; }\n","    div#menubar-container     { width: 65%; }\n","    div#maintoolbar-container { width: 99%; }\n","</style>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"metadata":{"colab_type":"text","id":"q7o09bmgJbq-"},"cell_type":"markdown","source":["## 2. Auxiliary functions"]},{"metadata":{"colab_type":"code","id":"WikMlK2sJbrB","colab":{}},"cell_type":"code","source":["def drop_descriptive_columns(dataset):\n","    \"\"\"\n","    Removes from a dataset, descriptive columns before using it for training the classifiers\n","    @param dataset: the dataset enriched with features\n","    @return: the new 'cleaned' dataset\n","    \"\"\"\n","    for c in dataset.columns:\n","        if c in ['RequirementText', 'Class', 'ProjectID']:\n","            dataset = dataset.drop(c, axis = 1)\n","    return dataset\n","\n","def split_tr_te(dataset, target, to_drop):\n","    \"\"\"\n","    Splits a dataset in training and test set (75 and 25%)\n","    @param dataset: the dataset to split\n","    @param target: the target class\n","    @param to_drop: some additional columns to drop before splitting\n","    @return: a tuple train_x, test_x, train_y, test_y, with y the target column, x the rest\n","    \"\"\"\n","    return train_test_split(dataset.drop(to_drop, axis=1), dataset[target], test_size=0.25, random_state=42)\n","    \n","def print_scores(actual, pred, name, prob):\n","    \"\"\"\n","    Prints the confusion matrix given the results of a classifier and calculates precision, recall, f1 and AUC score\n","    @param actual: the original annotation of the dataset (to use for the comparison in order to calculate the above metrics)\n","    @param pred: the predictions made by the classifier\n","    @param name: some textual variable to use for verbosity purposes\n","    @param prob: vector with the probabilities for the predictions in pred\n","    @return: a list [name, precision, recall, f1, auc]\n","    \"\"\"\n","    f1 = f1_score(actual, pred, average='micro') \n","    prec = precision_score(actual, pred) \n","    rec = recall_score(actual, pred) \n","    auc = roc_auc_score(actual, prob)\n","    print('=====', name)\n","    print('Confusion matrix (test)\\n', confusion_matrix(actual, pred))\n","#     print('F1-Score (micro)', f1)\n","#     print('Precision', prec)\n","#     print('Recall (train)', rec, '\\n')\n","    return [name, prec, rec, f1, auc]\n","    \n","  \n","def build_plot(y_true=[], scores=[], labels=[]):\n","    \"\"\"\n","    Generates two plots: a roc plot and a preision/recall plot\n","    \"\"\"\n","    gradient = np.linspace(0, 1, 10)\n","    color_list = [ cm.tab10(x) for x in gradient ]\n","\n","    fig, axes = plt.subplots(1, 2, figsize=(12, 5),\n","                         sharex=True, sharey=True)\n","    ax = axes[0]\n","    n_line = 0\n","    for i_score, score in enumerate(scores):\n","        fpr, tpr, _ = roc_curve(y_true[n_line], score, drop_intermediate=False)\n","        n_line = n_line + 1\n","        ax.plot(fpr, tpr, linestyle='-.', c=color_list[i_score], lw=1, label=labels[i_score])\n","    ax.set_title(\"ROC\", fontsize=20)\n","    ax.set_xlabel('False Positive Rate', fontsize=18)\n","    ax.set_ylabel('True Positive Rate (Recall)', fontsize=18)\n","    ax.legend(loc='lower center', fontsize=8)\n","\n","    ax = axes[1]\n","    n_line = 0\n","    for i_score, score in enumerate(scores):\n","        precision, recall, _ = precision_recall_curve(y_true[n_line], score)\n","        n_line = n_line + 1\n","        ax.step(recall, precision, linestyle='-.', c=color_list[i_score], lw=1, where='post', label=labels[i_score])\n","    ax.set_title(\"Precision-Recall\", fontsize=20)\n","    ax.set_xlabel('Recall (True Positive Rate)', fontsize=18)\n","    ax.set_ylabel('Precision', fontsize=18)\n","    ax.legend(loc='lower center', fontsize=8)\n","    plt.show()\n","\n","        \n","def train_classifier(model, train_x, train_y, name):\n","    \"\"\"\n","    Train a classifier and returns the fit scores for the training set\n","    \"\"\"\n","    model.fit(train_x, train_y)\n","    pred_train = model.predict(train_x)\n","    prob = model.predict_proba(train_x)[:, 1]\n","    scores_line = print_scores(train_y, pred_train, name, prob)\n","    return scores_line, pred_train, prob\n","  \n","def evaluate_classifier(model, test_x, test_y, name):\n","    \"\"\"\n","    Executes the classifiers on the test set and returns the obtained scores\n","    \"\"\"\n","    pred_test = model.predict(test_x)\n","    prob = model.predict_proba(test_x)[:, 1]\n","    scores_line = print_scores(test_y, pred_test, name, prob)\n","    return scores_line, pred_test, prob\n","  \n","def makeOverSamplesADASYN(X,y):\n","  \"\"\"\n","  Creates new data with oversampled variables by using ADASYN\n","  @param X: Independent Variable in DataFrame\n","  @param y: dependent variable in Pandas DataFrame formats\n","  @return: an oversampled version of the variables\n","  \"\"\"\n","  sm = ADASYN()\n","  X, y = sm.fit_sample(X, y)\n","  return X, y\n","\n","def make_roc_curve(appendix, target, to_drop, golds, probs, names, scores, nrfeat, colors):\n","  \"\"\"\n","  Generates a ROC plot (used in the paper)\n","  \"\"\"\n","  cv = StratifiedKFold(n_splits=10)\n","  classifier = svm.SVC(kernel='linear', probability=True, random_state=0)\n","\n","  # For fast processing\n","  # from sklearn.ensemble import GradientBoostingClassifier\n","  # classifier = GradientBoostingClassifier(random_state=42, n_estimators=30, max_depth = 5)\n","\n","  tprs = []\n","  aucs = []\n","  paucs = []\n","  ptprs = []\n","  mean_fpr = np.linspace(0, 1, 100)\n","  pmean_fpr = np.linspace(0, 1, 100)\n","\n","  plt.figure(figsize=(10,6))\n","\n","  dataz = pd.read_csv(folder_datasets+'promise-reclass' + '-' + appendix + '.csv', engine='python')\n","\n","  # Attempt with project-based fold -- TODO: try another partitioning\n","  # projects = [[3, 9, 11], [1, 5, 12], [6, 10, 13], [1, 8, 14], [3, 10, 12], [2, 5, 11], [4, 6, 14], [7, 8, 13], [2, 9, 15], [4, 7, 15] ]\n","  projects = [[3, 9, 11], [1, 5, 12], [6, 10, 13], [1, 8, 14], [3, 12, 15], [2, 5, 11], [6, 9, 14], [7, 8, 13], [2, 4, 15], [4, 7, 10] ]\n","  \n","  print (target + 'p-fold')\n","  prec = 0.0\n","  rec = 0.0\n","  f1 = 0.0\n","  for k in projects:\n","    mytest = dataz.loc[dataz['ProjectID'].isin(k)]\n","    mytrain = dataz.loc[~dataz['ProjectID'].isin(k)]\n","    mytest = drop_descriptive_columns(mytest)\n","    mytest = mytest.drop(mytest.columns[0], axis=1)\n","    mytrain = drop_descriptive_columns(mytrain)\n","    mytrain = mytrain.drop(mytrain.columns[0], axis=1)\n","    myprobs = classifier.fit(mytrain.drop(to_drop, axis=1), \n","                             mytrain[target]).predict_proba(mytest.drop(to_drop, axis=1))\n","    pred = classifier.predict(mytest.drop(to_drop, axis=1))\n","    prec += precision_score(mytest[target].values.tolist(), pred) \n","    rec += recall_score(mytest[target].values.tolist(), pred)\n","    f1 += f1_score(mytest[target].values.tolist(), pred)\n","    print (k, 'Precision', prec, 'Recall', rec )\n","    myfpr, mytpr, _ = roc_curve(mytest[target].values.tolist(), myprobs[:, 1], drop_intermediate=False)\n","    ptprs.append(interp(pmean_fpr, myfpr, mytpr))\n","    ptprs[-1][0] = 0.0\n","    my_auc = auc(myfpr, mytpr)\n","#     my_auc = roc_auc_score(mytest[target].values.tolist(), myprobs[:, 1])\n","    paucs.append(my_auc)\n","    plt.plot(myfpr, mytpr, lw=1, color=colors['Promise test'], alpha=0.8, linestyle='--',\n","                 label='Projects bundle %s (AUC = %0.2f)' % (str(k), my_auc))\n","\n","  print ('p-fold', 'Precision', str(prec/10.0), 'Recall', str(rec/10.0), 'F1', str(f1/10.0), 'AUC', str(my_auc/10.0))  \n","\n","  pmean_tpr = np.mean(ptprs, axis=0)\n","  pmean_tpr[-1] = 1.0\n","#   pmean_auc = auc(pmean_fpr, pmean_tpr)\n","  pmean_auc = np.mean(paucs, axis=0)\n","  std_auc = np.std(paucs)\n","  plt.plot(pmean_fpr, pmean_tpr, color=colors['Promise test'], linestyle='--',\n","           label=r'Mean p-fold (AUC = %0.2f $\\pm$ %0.2f)' % (pmean_auc, std_auc),\n","           lw=2, alpha=.8)\n","\n","  std_tpr = np.std(ptprs, axis=0)\n","  tprs_upper = np.minimum(pmean_tpr + std_tpr, 1)\n","  tprs_lower = np.maximum(pmean_tpr - std_tpr, 0)\n","  plt.fill_between(pmean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n","                   label=r'$\\pm$ 1 std. dev. from p-fold')\n","  \n","  plt.xlim([-0.01, 1.01])\n","  plt.ylim([-0.01, 1.01])\n","  plt.xlabel('False Positive Rate')\n","  plt.ylabel('True Positive Rate')\n","  #plt.title('Receiver operating characteristic')\n","  plt.legend(loc=\"lower right\")\n","  plt.show()\n","\n","  plt.figure(figsize=(10,6))\n","  \n","  dataz = drop_descriptive_columns(dataz)\n","  dataz = dataz.drop(dataz.columns[0], axis=1)\n","\n","  X = dataz.drop(to_drop, axis=1)\n","  y = dataz[target]\n","\n","  # This code plots the ROC curve with cross validation\n","  print (target + 'k-fold')\n","  i = 0\n","  prec = 0.0\n","  rec = 0.0\n","  f1 = 0.0\n","  for train, test in cv.split(X, y):\n","      probas_ = classifier.fit(X.iloc[train], y.iloc[train]).predict_proba(X.iloc[test])\n","      pred = classifier.predict(X.iloc[test])\n","      prec += precision_score(y.iloc[test], pred) \n","      rec += recall_score(y.iloc[test], pred)\n","      f1 += f1_score(y.iloc[test], pred)\n","      print (i, 'Precision', prec, 'Recall', rec )\n","      # Compute ROC curve and area the curve\n","      fpr, tpr, thresholds = roc_curve(y.iloc[test], probas_[:, 1], drop_intermediate=False)\n","      tprs.append(interp(mean_fpr, fpr, tpr))\n","      tprs[-1][0] = 0.0\n","      roc_auc = auc(fpr, tpr)\n","#       roc_auc = roc_auc_score(y.iloc[test], probas_[:, 1])\n","      aucs.append(roc_auc)\n","      plt.plot(fpr, tpr, lw=1, alpha=0.3,\n","               label='k-fold %d (AUC = %0.2f)' % (i, roc_auc))\n","      i += 1\n","\n","  print ('k-fold', 'Precision', str(prec/10.0), 'Recall', str(rec/10.0), 'F1', str(f1/10.0), 'AUC', str(roc_auc/10))\n","\n","  plt.xlim([-0.01, 1.01])\n","  plt.ylim([-0.01, 1.01])\n","  plt.xlabel('False Positive Rate')\n","  plt.ylabel('True Positive Rate')\n","  #plt.title('Receiver operating characteristic')\n","  plt.legend(loc=\"lower right\")\n","  plt.show()\n","\n","# plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n","#          label='Chance', alpha=.8)\n","\n","  plt.plot(pmean_fpr, pmean_tpr, color=colors['Promise test'], linestyle=':',\n","           label=r'Mean p-fold (AUC = %0.2f $\\pm$ %0.2f)' % (pmean_auc, std_auc),\n","           lw=2, alpha=.8)\n","\n","  mean_tpr = np.mean(tprs, axis=0)\n","  mean_tpr[-1] = 1.0\n","#   mean_auc = auc(mean_fpr, mean_tpr)\n","  mean_auc = np.mean(aucs, axis=0)\n","  std_auc = np.std(aucs)\n","  plt.plot(mean_fpr, mean_tpr, color=colors['Promise test'], linestyle='--',\n","           label=r'Mean k-fold (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n","           lw=2, alpha=.8)\n","\n","  std_tpr = np.std(tprs, axis=0)\n","  tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n","  tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n","  plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n","                   label=r'$\\pm$ 1 std. dev. from k-fold')\n","\n","\n","  idx = 0\n","  #colors = ['green', 'brown', 'darkolivegreen', 'purple', 'yellow', 'black', 'red', 'peru']\n","  for gold in golds:\n","    fpr, tpr, thresholds = roc_curve(gold, probs[idx])\n","#     the_auc = auc(fpr, tpr)\n","    plt.plot(fpr, tpr, lw=2, color=colors[names[idx]], alpha=0.8,\n","               label='%s (AUC = %0.2f)' % (names[idx], scores[idx]))\n","    idx += 1\n","\n","\n","  plt.xlim([-0.01, 1.01])\n","  plt.ylim([-0.01, 1.01])\n","  plt.xlabel('False Positive Rate')\n","  plt.ylabel('True Positive Rate')\n","  #plt.title('Receiver operating characteristic')\n","  #plt.legend(loc=\"lower right\")\n","\n","  handles, labels = plt.gca().get_legend_handles_labels()\n","  order = [2, 1, 0]\n","  \n","  for i in range(3, len(handles)):\n","    order.append(i)\n","  \n","  print ('The order is', order)\n","  plt.legend([handles[idx] for idx in order],[labels[idx] for idx in order],loc=\"lower right\")\n","\n","  #plt.show()\n","  print ('roc-' + str(nrfeat) + '-' + appendix + '.pdf')\n","  plt.savefig('roc-' + str(nrfeat) + '-' + appendix + '.pdf', dpi=300, bbox_inches='tight')"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"FgW5Yr4QRmJ5"},"cell_type":"markdown","source":["## 3a. Precision, recall, F1, ROC curve\n","\n","Imports the classified and **enriched** dataset, calculates precision, recall, F1 score and plots the ROC curve"]},{"metadata":{"colab_type":"code","id":"_xXXqVdxtfyj","outputId":"b32d5a15-6ac9-4712-be25-50e4e19aac80","executionInfo":{"status":"ok","timestamp":1554766252337,"user_tz":-120,"elapsed":7723115,"user":{"displayName":"Davide Dell'Anna","photoUrl":"https://lh5.googleusercontent.com/-dJU__MJ08Ww/AAAAAAAAAAI/AAAAAAAAbsA/YkubKaeFgQo/s64/photo.jpg","userId":"01259263475584376287"}},"colab":{"base_uri":"https://localhost:8080/","height":95176,"output_embedded_package_id":"1aWwdSxMpRVaG0wwnYPISjanfTQWBaLwI"}},"cell_type":"code","source":["folder_datasets = 'ling/' #can be an url\n","filenames = ['esa-eucl-est', 'ds2', 'ds3', 'dronology', 'reqview', 'leeds', 'wasp']\n","labels = ['ESA Euclid', 'Helpdesk', 'User mgmt', 'Dronology', 'ReqView', 'Leeds library', 'WASP']\n","remove = [('dronology', 'f'),('dronology', 'oq'),('wasp', 'f'),('wasp', 'oq')]\n","oversample = [('ds3', 'f'), ('ds3', 'oq')]\n","targets = ['IsFunctional', 'IsQuality', 'OnlyFunctional', 'OnlyQuality']\n","\n","colorpalette = ['#000000', '#e69f00', '#56b4e9', '#009e73', '#f0e442', '#0072b2', '#d55e00', '#cc79a7']\n","colors = {'Promise test' : colorpalette[0]}\n","for i in range(0, len(filenames)):\n","  colors.update({labels[i] : colorpalette[i+1]})\n","\n","pd.set_option('precision', 3)\n","\n","allfiles = ['Promise train', 'Promise test', 'Macro-average', 'Micro-average']\n","allfiles += labels\n","allresults = pd.DataFrame(allfiles, columns = ['Dataset']) \n","\n","feature_sets = ['FinalSel_vlist', 'FinalSel_verb', 'two', 'all', 'allext', 'sd', 'sdext', 'sdsb','sdsbext', 'sdsb8sel02', 'sdsb8sel02ext', 'seqext', 'evext', 'FinalSel', 'FinalSel7']\n","\n","# classify all datasets with all possible feature sets and for all target class.\n","# print the results and the plots\n","for feature_set in feature_sets:\n","  for target in targets:\n","    print(\"======== Results for feature set '\"+feature_set+\"' with target '\"+ target +\"' ========\")\n","\n","    to_drop = ['IsFunctional', 'IsQuality']\n","\n","    appendix = 'ling-'+feature_set\n","    \n","    #read the promise dataset, it is used to train the classifier, which will be then tested on all other datasets\n","    data = pd.read_csv(folder_datasets+'promise-reclass' + '-' + appendix + '.csv', engine='python')\n","    \n","    tag = ''\n","    if target=='IsFunctional':\n","      tag = 'f'\n","    if target=='IsQuality':\n","      tag = 'q'\n","    if target=='OnlyFunctional':\n","      tag = 'of'\n","      data['IsFunctional'] = data['IsFunctional'] & ~data['IsQuality'] #calculating the right value for the column\n","      target = 'IsFunctional'\n","    if target=='OnlyQuality':\n","      tag = 'oq'\n","      data['IsQuality'] = ~data['IsFunctional'] & data['IsQuality']\n","      target = 'IsQuality'\n","\n","   \n","    probs = []\n","    names = []\n","    golds = []\n","    auc_scores = []\n","    \n","    data = drop_descriptive_columns(data)\n","    \n","    #split promise in 75/25\n","    train_x, test_x, train_y, test_y = split_tr_te(data, target, to_drop) \n","    res = []\n","    #train the classifier on the 75% of promise\n","    model = SVC(kernel='linear', C=1, random_state=0, probability=True)\n","    scores_line, _, _ = train_classifier(model, train_x, train_y, 'Promise train') \n","    #test the performances on the remaining 25\n","    scores_line, svm_te, svm_pr = evaluate_classifier(model, test_x, test_y, 'Promise test')\n","    print (scores_line)\n","    res.append(scores_line)\n","    probs.append(svm_pr)\n","    names.append('Promise test')\n","    golds.append(test_y)\n","    auc_scores.append(scores_line[4])\n","    \n","    #retrain the classifier on entire promise and test it on the other datasets\n","    model.fit(data.drop(to_drop, axis=1), data[target])\n","    \n","    precisions = []\n","    recalls = []\n","    f1s = []\n","    aucs = []\n","    idx = 0\n","    for filename in filenames: #loop for all datasets\n","      print(filename)\n","      data3 = pd.read_csv(folder_datasets+filename + '-' + appendix + '.csv', engine='python')\n","      if target == 'OnlyQuality':\n","        data3['IsQuality'] = ~data3['IsFunctional'] & data3['IsQuality']\n","        target = 'IsQuality'\n","\n","      if target == 'OnlyFunctional':\n","        data3['IsFunctional'] = data3['IsFunctional'] & ~data3['IsQuality']\n","        target = 'IsFunctional'\n","        \n","      data3 = drop_descriptive_columns(data3)\n","      if (filename, tag) in oversample:\n","        print ('Oversampling', filename)\n","        X, y = makeOverSamplesADASYN(data3.drop(to_drop, axis=1), data3[target])\n","      else:\n","        X = data3.drop(to_drop, axis=1)\n","        y = data3[target]\n","      scores_line, svm_te, svm_pr = evaluate_classifier(model, X, y, filename)\n","      precisions.append(scores_line[1])\n","      recalls.append(scores_line[2])\n","      f1s.append(scores_line[3])\n","      aucs.append(scores_line[4])\n","      res.append(scores_line)\n","      if (filename, tag) not in remove:\n","        probs.append(svm_pr)\n","        names.append(labels[idx])\n","        auc_scores.append(scores_line[4])\n","        if (filename, tag) in oversample:\n","          golds.append(y)\n","        else:\n","          golds.append(y.values.tolist())\n","      idx = idx + 1\n","      \n","    res.append(['Macro-average', np.mean(precisions), np.mean(recalls), np.mean(f1s), np.mean(aucs)])\n","    res.append(['Std-dev', np.std(precisions), np.std(recalls), np.std(f1s), np.std(aucs)])\n","\n","    print(\"Feature set '\"+feature_set+\"' Target '\"+ target +\"' ========\")\n","    \n","    #display the results in the form of tables precision recall f1 auc, plots\n","    build_plot(y_true=golds, scores=probs, labels=names)\n","    make_roc_curve(appendix, target, to_drop, golds, probs, names, auc_scores, '', colors)  \n","    results = pd.DataFrame(res, columns = ['Dataset', 'Prec-' + appendix, 'Rec-' + appendix, 'F1-' + appendix, 'AUC-' + appendix]) \n","    display(HTML(results.to_html()))\n","\n","    allresults = pd.merge(allresults, results, on='Dataset')\n","\n","  display(HTML(allresults.to_html()))\n","\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}