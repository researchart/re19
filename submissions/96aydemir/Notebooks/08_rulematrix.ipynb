{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"08_rulematrix.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"colab_type":"text","id":"c4LfzHoKRUwk"},"cell_type":"markdown","source":["# RE19-classification: interpretable ML via RuleMatrix\n","\n"]},{"metadata":{"id":"Rc6N9-cf3lIE","colab_type":"text"},"cell_type":"markdown","source":["## Install the necessary packages for rule-matrix\n","\n"]},{"metadata":{"colab_type":"code","id":"inoDnAn5savZ","outputId":"1bf3c741-43a8-4c9e-b20e-493a8b350056","colab":{"base_uri":"https://localhost:8080/","height":343}},"cell_type":"code","source":["!git clone https://github.com/rulematrix/rule-matrix-py.git\n","!pip3 install rule-matrix-py/.\n","!pip3 install mdlp-discretization\n","!pip3 install pysbrl==0.4.2rc0\n","!pip3 install fim"],"execution_count":0,"outputs":[{"output_type":"stream","text":["fatal: destination path 'rule-matrix-py' already exists and is not an empty directory.\n","\u001b[31mDirectory 'rule-matrix-py/.' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\n","Requirement already satisfied: mdlp-discretization in /usr/local/lib/python3.7/site-packages (0.3.2)\n","Requirement already satisfied: scikit-learn>=0.18.1 in /usr/local/lib/python3.7/site-packages (from mdlp-discretization) (0.20.3)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/site-packages (from mdlp-discretization) (1.2.1)\n","Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/site-packages (from mdlp-discretization) (1.16.2)\n","Requirement already satisfied: pysbrl==0.4.2rc0 in /usr/local/lib/python3.7/site-packages (0.4.2rc0)\n","Requirement already satisfied: fim in /usr/local/lib/python3.7/site-packages (6.27)\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"D9z9eI1OReXJ"},"cell_type":"markdown","source":["## Imports"]},{"metadata":{"colab_type":"code","id":"5nFWJMhhsjed","colab":{}},"cell_type":"code","source":["import rulematrix\n","from rulematrix.surrogate import rule_surrogate\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.pipeline import Pipeline\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import load_breast_cancer, load_iris\n","\n","import pandas as pd\n","\n","from sklearn.svm import SVC\n","\n","import numpy as np\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"FgW5Yr4QRmJ5"},"cell_type":"markdown","source":["# Load the dataset"]},{"metadata":{"colab_type":"code","id":"_xXXqVdxtfyj","outputId":"163f851c-482e-486b-96f2-68b22f3d8022","colab":{"base_uri":"https://localhost:8080/","height":275}},"cell_type":"code","source":["def drop_descriptive_columns(dataset):\n","    for c in dataset.columns:\n","        if c in ['RequirementText', 'Class', 'ProjectID']:\n","            dataset = dataset.drop(c, axis = 1)\n","    return dataset\n","  \n","def split_tr_te(dataset, target, to_drop):\n","     return train_test_split(dataset.drop(to_drop, axis=1), dataset[target], test_size=0.25, random_state=42)\n","\n","def train_nn(neurons=(20,), **kwargs):\n","    model = MLPClassifier(hidden_layer_sizes=neurons, **kwargs)\n","    if is_categorical is not None:\n","        model = Pipeline([\n","            ('one_hot', OneHotEncoder(categorical_features=is_categorical)),\n","            ('mlp', model)\n","        ])\n","    model.fit(train_x, train_y)\n","    train_score = model.score(train_x, train_y)\n","    test_score = model.score(test_x, test_y)\n","    print('Training score:', train_score)\n","    print('Test score:', test_score)\n","    return model\n","  \n","def train_SVC(train_x, train_y):\n","  model = SVC(kernel='linear', C=1, random_state=0, probability=True)\n","  model.fit(train_x, train_y)\n","  train_score = model.predict(train_x)\n","  test_score = model.predict_proba(train_x)[:, 1]\n","#   scores_line = print_scores(train_y, pred_train, name)\n","#   print('Training score:', train_score)\n","#   print('Test score:', test_score)\n","  return model\n","\n","def train_surrogate(model, sampling_rate=2.0, **kwargs):\n","  \"\"\"\n","  trains rulematrix\n","  \"\"\"\n","    surrogate = rule_surrogate(model.predict, train_x, sampling_rate=sampling_rate,\n","                               is_continuous=is_continuous,\n","                               is_categorical=is_categorical,\n","                               is_integer=is_integer,\n","                               rlargs={'feature_names': feature_names, 'verbose': 2},\n","                               **kwargs)\n","\n","    train_fidelity = surrogate.score(train_x)\n","    test_fidelity = surrogate.score(test_x)\n","    print('Training fidelity:', train_fidelity)\n","    print('Test fidelity:', test_fidelity)\n","    return surrogate\n","\n","\n","folder_datasets = '../datasets/re19_ling_datasets/'\n","\n","filenames = ['promise-reclass', 'INDcombined', '8combined']\n","targets = ['IsFunctional', 'IsQuality', 'OnlyFunctional', 'OnlyQuality']\n","feature_sets = ['sd', 'sdsb8sel02ext']\n","#UNCOMMENT AND SET THE FOLLOWING FOR THE VISUALIZATION (SEE COMMENT AT THE END OF THE FILE)\n","# target = 'IsFunctional'\n","# filename = 'promise-reclass-'\n","# appendix = 'ling-'+'allext'\n","# appendix = 'f'\n","\n","\n","for target in targets:\n","    for feature_set in feature_sets:\n","        for filename in filenames:\n","            print('======== Target '+target +' Feature set '+feature_set+' Dataset '+filename+ ' ========')\n","            appendix='-ling-'+feature_set\n","\n","            data = pd.read_csv(folder_datasets+filename + appendix + '.csv', engine='python')\n","\n","            data = drop_descriptive_columns(data)\n","            # data = data.drop(['RequirementText', 'Class', 'ProjectID'], axis = 1)\n","            data = data.drop(data.columns[0], axis=1)\n","\n","            nunique = data.apply(pd.Series.nunique)\n","            cols_to_drop = nunique[nunique == 1].index\n","            data = data.drop(cols_to_drop, axis=1)\n","\n","            to_drop = ['IsFunctional', 'IsQuality']\n","            if target == 'OnlyQuality':\n","                data['IsQuality'] = ~data['IsFunctional'] & data['IsQuality']\n","                target = 'IsQuality'\n","\n","            if target == 'OnlyFunctional':\n","                data['IsFunctional'] = data['IsFunctional'] & ~data['IsQuality']\n","                target = 'IsFunctional'\n","\n","            train_x, test_x, train_y, test_y = split_tr_te(data, target, to_drop)\n","\n","\n","            is_integer = []\n","            is_continuous = []\n","            is_categorical = []\n","            for d in data.drop(to_drop, axis=1).dtypes:\n","              if d == 'int64' or d == 'int32':\n","                is_integer.append(True)\n","              else:\n","                is_integer.append(False)\n","              if d == 'float64' or d == 'float32':\n","                is_continuous.append(True)\n","              else:\n","                is_continuous.append(False)\n","\n","            feature_names = []\n","            for fn in data.drop(to_drop, axis=1).columns:\n","              if fn != target:\n","                feature_names.append(fn)\n","\n","            target_names = data[target].unique()\n","            is_categorical = None\n","            #is_integer = None\n","\n","            print (is_continuous, is_categorical, is_integer, feature_names, target_names)\n","\n","            print (data.head())\n","\n","            # neural network\n","            # nn = train_nn((20, 20, 20), random_state=43, max_iter=250)\n","\n","            #svm\n","            svc = train_SVC(train_x, train_y)\n","\n","            #train rulematrix\n","            surrogate = train_surrogate(svc, 4, seed=44)\n","            #determine the rules\n","            rl = surrogate.student\n","            print(rl)\n","\n","            # UNCOMMENT THIS TO SEE THE VISUALIZATION.\n","            # NOTE: THE VISUALIZATION DOES NOT WORK WITHIN A LOOP,\n","            # SO TO USE IT, SET THE VARIABLES BEFORE THE LOOP AND REMOVE THE LOOP\n","\n","            # rulematrix.render(train_x.values.astype('float64'), train_y.values.astype('float64'), surrogate,feature_names=feature_names, target_names=target_names, is_categorical=is_categorical)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["======== Target IsFunctional Feature set sd Dataset promise-reclass ========\n","[False, False, False, False, False, False, False, False, False, False, False, False, False, False] None [True, True, True, True, True, True, True, True, True, True, True, True, True, True] ['Length', 'dobj', 'nummod', 'acl', 'amod', 'auxpass', 'advmod', 'nsubjpass', 'nsubj', 'nmod', 'aux', 'pobj', 'prep', 'det'] [1 0]\n","   IsFunctional  IsQuality  Length  dobj  nummod  acl  amod  auxpass  advmod  \\\n","0             1          1      56     1       1    0     0        0       0   \n","1             0          1      98     1       0    1     0        0       0   \n","2             0          1     158     1       1    0     1        0       0   \n","3             0          1     197     1       1    0     1        0       1   \n","4             0          1     203     0       1    0     1        0       0   \n","\n","   nsubjpass  nsubj  nmod  aux  pobj  prep  det  \n","0          0      1     0    1     0     0    1  \n","1          0      1     0    1     1     1    1  \n","2          0      1     1    1     1     1    1  \n","3          0      1     0    1     1     1    1  \n","4          0      1     0    1     1     1    1  \n","Training fidelity: 1.0\n","Test fidelity: 1.0\n","The rule list contains 4 of rules:\n","\n","     IF (dobj in (1.5, inf)) THEN prob: [0.0133, 0.9867]\n","\n","ELSE IF (nummod in (0.5, inf)) THEN prob: [0.9981, 0.0019]\n","\n","ELSE IF (dobj in (-inf, 0.5)) THEN prob: [0.9504, 0.0496]\n","\n","ELSE DEFAULT prob: [0.0011, 0.9989]\n","\n","======== Target IsFunctional Feature set sd Dataset INDcombined ========\n","[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False] None [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True] ['Length', 'dobj', 'nummod', 'acl', 'amod', 'auxpass', 'advmod', 'nsubjpass', 'nsubj', 'nmod', 'aux', 'pobj', 'prep', 'det', 'punct'] [0 1]\n","   IsFunctional  IsQuality  Length  dobj  nummod  acl  amod  auxpass  advmod  \\\n","0             0          1      91     0       0    0     1        1       0   \n","1             0          1     128     1       0    0     1        1       0   \n","2             1          0     168     1       0    1     1        1       1   \n","3             1          0     220     1       0    1     0        0       1   \n","4             1          0     235     1       0    1     1        0       0   \n","\n","   nsubjpass  nsubj  nmod  aux  pobj  prep  det  punct  \n","0          1      1     0    1     1     1    1      1  \n","1          1      1     0    1     1     1    1      1  \n","2          1      1     0    1     1     1    1      1  \n","3          0      1     0    1     1     1    1      1  \n","4          0      1     0    1     1     1    1      1  \n","Training fidelity: 0.9954337899543378\n","Test fidelity: 0.9954545454545455\n","The rule list contains 6 of rules:\n","\n","     IF (dobj in (-inf, 0.5)) THEN prob: [0.9875, 0.0125]\n","\n","ELSE IF (nummod in (-inf, 0.5)) THEN prob: [0.0005, 0.9995]\n","\n","ELSE IF (Length in (118.0, inf)) THEN prob: [0.1000, 0.9000]\n","\n","ELSE IF (acl in (0.0, inf)) THEN prob: [0.6250, 0.3750]\n","\n","ELSE IF (pobj in (-inf, 1.0)) THEN prob: [0.9405, 0.0595]\n","\n","ELSE DEFAULT prob: [0.3333, 0.6667]\n","\n","======== Target IsFunctional Feature set sd Dataset 8combined ========\n","[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False] None [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True] ['Length', 'dobj', 'nummod', 'acl', 'amod', 'auxpass', 'advmod', 'nsubjpass', 'nsubj', 'nmod', 'aux', 'pobj', 'prep', 'det', 'punct'] [1 0]\n","   IsFunctional  IsQuality  Length  dobj  nummod  acl  amod  auxpass  advmod  \\\n","0             1          1      56     1       1    0     0        0       0   \n","1             0          1      98     1       0    1     0        0       0   \n","2             0          1     158     1       1    0     1        0       0   \n","3             0          1     197     1       1    0     1        0       1   \n","4             0          1     203     0       1    0     1        0       0   \n","\n","   nsubjpass  nsubj  nmod  aux  pobj  prep  det  punct  \n","0          0      1     0    1     0     0    1      1  \n","1          0      1     0    1     1     1    1      1  \n","2          0      1     1    1     1     1    1      1  \n","3          0      1     0    1     1     1    1      1  \n","4          0      1     0    1     1     1    1      1  \n","Training fidelity: 1.0\n","Test fidelity: 1.0\n","The rule list contains 4 of rules:\n","\n","     IF (dobj in (0.5, 1.0)) AND (nummod in (-0.5, 0.5)) THEN prob: [0.0004, 0.9996]\n","\n","ELSE IF (dobj in (1.0, inf)) THEN prob: [0.0093, 0.9907]\n","\n","ELSE IF (nummod in (-inf, -0.5)) THEN prob: [0.0303, 0.9697]\n","\n","ELSE DEFAULT prob: [0.9994, 0.0006]\n","\n","======== Target IsFunctional Feature set allext Dataset promise-reclass ========\n","[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False] None [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True] ['Length', 'AdvMod', 'AMod', 'AComp', 'DTreeHeight', 'dobj', 'nummod', 'acl', 'amod', 'auxpass', 'advmod', 'nsubjpass', 'nsubj', 'nmod', 'advcl', 'ROOT+nummod', 'aux+nummod', 'det+nummod', 'nummod+punct', 'ROOT+dobj', 'aux+dobj', 'nummod+pobj', 'nsubj+dobj', 'nsubj+nummod', 'dobj+pobj', 'ROOT+nummod+punct', 'aux+ROOT+nummod', 'aux+nummod+punct', 'det+ROOT+nummod', 'det+nummod+punct', 'det+aux+nummod', 'ROOT+det+dobj', 'nsubj+det+dobj', 'aux+det+dobj', 'nsubj+aux+dobj', 'ROOT_dobj_det', 'ROOT_dobj_acl_aux', 'ROOT_dobj_acl_dobj_det', 'ROOT_prep_pobj_det', 'ROOT_auxpass', 'ROOT_prep_pobj_compound', 'ROOT_nsubj', 'ROOT_ccomp_aux', 'ROOT_nsubj_nummod', 'ROOT_prep_pobj_nummod', 'ROOT_dobj_det+ROOT_nsubj_det', 'ROOT_aux+ROOT_dobj_det', 'ROOT_dobj_det+ROOT_punct', 'ROOT_aux+ROOT_dobj_acl_aux', 'ROOT_dobj_acl_aux+ROOT_dobj_det', 'ROOT_dobj_acl_aux+ROOT_punct', 'ROOT_dobj_acl_aux+ROOT_nsubj_det', 'ROOT_prep_pobj_det+ROOT_punct', 'ROOT_aux+ROOT_dobj_det+ROOT_nsubj_det', 'ROOT_dobj_det+ROOT_nsubj_det+ROOT_punct', 'ROOT_aux+ROOT_dobj_det+ROOT_punct', 'ROOT_aux+ROOT_aux+ROOT_punct', 'ROOT_aux+ROOT_punct+ROOT_punct', 'ROOT_aux+ROOT_aux+ROOT_nsubj_det', 'ROOT_nsubj_det+ROOT_punct+ROOT_punct', 'ROOT_aux+ROOT_dobj_acl_aux+ROOT_dobj_det', 'ROOT_aux+ROOT_dobj_acl_aux+ROOT_punct', 'ROOT_dobj_acl_aux+ROOT_dobj_det+ROOT_punct', 'Modal', 'Adjective', 'Noun', 'Adverb', 'Cardinal', 'CompSupAdj', 'CompSupAdv', 'Words', 'TreeHeight', 'SubTrees'] [1 0]\n","   IsFunctional  IsQuality  Length  AdvMod  AMod  AComp  DTreeHeight  dobj  \\\n","0             1          1      56       0     0      0            3     1   \n","1             0          1      98       0     0      0           10     1   \n","2             0          1     158       0     0      1            7     1   \n","3             0          1     197       1     2      2            7     1   \n","4             0          1     203       0     1      1            8     0   \n","\n","   nummod  acl  ...  Modal  Adjective  Noun  Adverb  Cardinal  CompSupAdj  \\\n","0       1    0  ...      1          0     1       0         1           0   \n","1       0    1  ...      1          0     3       0         0           0   \n","2       1    0  ...      2          2     2       0         3           0   \n","3       1    0  ...      2          4     2       2         2           0   \n","4       1    0  ...      2          3     3       0         3           0   \n","\n","   CompSupAdv  Words  TreeHeight  SubTrees  \n","0           0      9           6         4  \n","1           0     16          13         3  \n","2           0     29          14         6  \n","3           0     36          12         6  \n","4           0     35          18         4  \n","\n","[5 rows x 75 columns]\n"],"name":"stdout"},{"output_type":"error","ename":"LinAlgError","evalue":"singular matrix","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-fdca594ff87f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0msvc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_SVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0msurrogate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_surrogate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m44\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0mrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msurrogate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstudent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-40-fdca594ff87f>\u001b[0m in \u001b[0;36mtrain_surrogate\u001b[0;34m(model, sampling_rate, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m                                \u001b[0mis_integer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_integer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                                \u001b[0mrlargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'feature_names'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'verbose'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                                **kwargs)\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mtrain_fidelity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msurrogate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/site-packages/rulematrix/surrogate/surrogate.py\u001b[0m in \u001b[0;36mrule_surrogate\u001b[0;34m(target, train_x, is_continuous, is_categorical, is_integer, ranges, cov_factor, sampling_rate, seed, rlargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m                            ranges, cov_factor, sampling_rate, seed)\n\u001b[1;32m    152\u001b[0m     \u001b[0;31m# Fit the distribution estimation of training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0msurrogator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msurrogator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/site-packages/rulematrix/surrogate/surrogate.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Passing y to the fitting function, y will not be used!'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_instances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0msampled_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/site-packages/rulematrix/surrogate/surrogate.py\u001b[0m in \u001b[0;36mfit_distribution\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \"\"\"\n\u001b[1;32m     96\u001b[0m         self.data_distribution = create_sampler(X, self.is_continuous, self.is_categorical, self.is_integer,\n\u001b[0;32m---> 97\u001b[0;31m                                                 self.ranges, self.cov_factor, seed=self.seed)\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_instances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/site-packages/rulematrix/surrogate/sample.py\u001b[0m in \u001b[0;36mcreate_sampler\u001b[0;34m(instances, is_continuous, is_categorical, is_integer, ranges, cov_factor, seed, verbose)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;31m# Estimate the covariance matrix for kde\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_numeric\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mglb_kde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinuous_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'silverman'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcov_factor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mglb_kde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, bw_method, weights)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_neff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weights\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_bandwidth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36mset_bandwidth\u001b[0;34m(self, bw_method)\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compute_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36m_compute_covariance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    550\u001b[0m                                                \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                                                aweights=self.weights))\n\u001b[0;32m--> 552\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_inv_cov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_covariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_covariance\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/site-packages/scipy/linalg/basic.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0minv_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlwork\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite_lu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m         raise ValueError('illegal value in %d-th argument of internal '\n","\u001b[0;31mLinAlgError\u001b[0m: singular matrix"]}]}]}